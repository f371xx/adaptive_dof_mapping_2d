{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Dataset handling\n",
    "Dataset class with \n",
    "- Loading\n",
    "- Prepocessing\n",
    "- Printing\n",
    "\n",
    "Also includes pretty-print functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.set_memory_growth((tf.config.list_physical_devices('GPU'))[0], True)\n",
    "import os, numpy as np, sys, matplotlib.pyplot as plt, matplotlib.patches as patches, matplotlib, json, cv2, math\n",
    "import custom_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Dataset2d():\n",
    "    \"\"\" Class for handling 2D Datasets\n",
    "    \"\"\"\n",
    "    ## Constants\n",
    "    VELOCITY_FACTORS = tf.constant([1.,1.,50./70., 50/0.01]) # Factor of velocities for normalisation\n",
    "    BATCH_SIZE_SEQUENCE = \"sequence\" # reference value as alternative for batch size\n",
    "    DEFAULT_SETTINGS = {\n",
    "            \"step_size\":1,\n",
    "            \"random_seed\": 13,\n",
    "            \"train_test_ratio\": 10, # 1/ratio will be size of test set\n",
    "            \"batch_size\": 32, # integer or BATCH_SIZE_SEQUENCE. If BATCH_SIZE_SEQUENCE, will use the individual sequences\n",
    "            \"render_images\": False, # if true, renders images instead of a feature vector\n",
    "            \"render_poles\": False, # if render_images == True and this is set, poles are being drawn onto the squares\n",
    "            \"filter_zeros\": True, # whether to filter lines with zero-velocities. Not everything tested if False. Also deactivates vector normalisation \n",
    "    }\n",
    "    def __init__(self, path, settings={}, name=\"\"):\n",
    "        \"\"\"Creates the Dataset object. \n",
    "            param path: The filepath of the Dataset\n",
    "            param settings: An optinal dict with the setting options\n",
    "            param name: An optional string name of the dataset\n",
    "        \"\"\"\n",
    "        self.path, self.name, self.settings = path + \"/\", name, self.DEFAULT_SETTINGS.copy()\n",
    "        for s in settings.keys(): # store given settings\n",
    "            if s in self.settings.keys(): \n",
    "                self.settings[s] = settings[s]\n",
    "                if s == \"batch_size\" and type(settings[s])!=int and settings[s]!=self.BATCH_SIZE_SEQUENCE:\n",
    "                    raise Exception(f\"{settings[s]} not a valid batch_size value. Should be int or '{self.BATCH_SIZE_SEQUENCE}'\")\n",
    "            else: raise Exception(f\"{s} not a valid setting. Try: {self.DEFAULT_SETTINGS}\")\n",
    "        np.random.seed(self.settings[\"random_seed\"]) # Seed the randomness\n",
    "        if(self.settings['render_images']):\n",
    "            self.transformEnvironment = self.transformEnvironment_to_rgb\n",
    "            if(not self.settings['render_poles']):\n",
    "                self.drawPoles = lambda _,_1,_2:None\n",
    "        self.__loadSequences() # load csv files\n",
    "        self.__storeTestTrain()# prepare tensors\n",
    "    \n",
    "    def __loadSequences(self):\n",
    "        \"\"\"Reads the csv files and loads them as sequences in the self.sequences list. Shuffles the list\"\"\"\n",
    "        self.sequences = []\n",
    "        def getCsvFilesRecursive(p):\n",
    "            files = [p+\"/\"+f for f in os.listdir(p) if f.endswith(\".csv\")] # get csv file \n",
    "            for d in [p+\"/\"+d for d in os.listdir(p) if os.path.isdir(p+\"/\"+d)]: files +=getCsvFilesRecursive(d) # get lower directories\n",
    "            return files        \n",
    "        files = getCsvFilesRecursive(self.path) # load all CSV files\n",
    "        for file in files: # load csv file\n",
    "            csv = np.loadtxt(file, delimiter=',', skiprows=1, usecols=[i for i in range(12)], dtype=np.float32 )\n",
    "            if(self.settings['filter_zeros']):\n",
    "                csv = csv[np.any(csv[:,:4]!=0, axis=1) | np.all(csv==0, axis=1)] # remove zero-vel-vectors\n",
    "            restarts = np.all(csv==0, axis=1) # restarts are represented as all-0 rows\n",
    "            restarts = [-1]+[i for i,v in enumerate(restarts) if v]+[len(restarts)]\n",
    "            self.sequences += [csv[v+1:restarts[i+1]:self.settings[\"step_size\"]] for i,v in enumerate(restarts[:-1]) if len(csv[v+1:restarts[i+1]:self.settings[\"step_size\"]])!=0]\n",
    "        np.random.shuffle(self.sequences) # Shuffle the sequences, not within an individual sequence\n",
    "    \n",
    "    def __storeCovariances(self):\n",
    "        \"\"\"Calculates and stores dataset covariances internally\"\"\"\n",
    "        def getEig(dataset):\n",
    "            labels = np.vstack(dataset)[:,:4]\n",
    "            if(self.settings['filter_zeros']):\n",
    "                labels /= np.linalg.norm(labels, axis=-1, keepdims=True) # normalize labels\n",
    "            sigma = tf.matmul(labels, labels, transpose_a=True) \n",
    "            sigma = sigma / len(labels)\n",
    "            eigVals, eigVects = tf.linalg.eigh(sigma)\n",
    "            return sigma.numpy(), eigVals.numpy()[::-1], eigVects.numpy()[:,::-1]\n",
    "        self.train_cov, self.train_eigVals, self.train_eigVects = getEig(self._train_pure)\n",
    "        self.test_cov, self.test_eigVals, self.test_eigVects = getEig(self._test_pure)\n",
    "    \n",
    "    def __storeTestTrain(self):\n",
    "        \"\"\"Split data in test and train sections and store internally\"\"\"\n",
    "        testDivisor = len(self.sequences)//self.settings[\"train_test_ratio\"]\n",
    "        self._test_pure, self._train_pure = self.sequences[:testDivisor], self.sequences[testDivisor:]\n",
    "        self.__storeCovariances()\n",
    "        self.test_num_sequences, self.train_num_sequences = len(self._test_pure), len(self._train_pure) \n",
    "        self.test_num_datapoints, self.train_num_datapoints = (sum([len(t) for t in dataset]) for dataset in [self._test_pure, self._train_pure])\n",
    "        if self.settings[\"batch_size\"] == self.BATCH_SIZE_SEQUENCE:\n",
    "            test, train = ([tf.convert_to_tensor(v) for v in dt] for dt in (self._test_pure, self._train_pure))\n",
    "            self.test, self.train = (tf.data.Dataset.from_generator(lambda:(d for d in ds), \n",
    "                                        output_types=(tf.float32), output_shapes=(None,12)) \\\n",
    "                                     .cache().shuffle(dl) \\\n",
    "                                     .map(self.normaliseDatapoint, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "                                     .prefetch(tf.data.experimental.AUTOTUNE) \\\n",
    "                                     for ds, dl in zip((test, train),(self.test_num_sequences, self.train_num_sequences)))\n",
    "        else: # Stack sequences to dataset, cache and shuffle it, batch, map and prefetch\n",
    "            self.test, self.train = (tf.data.Dataset.from_tensor_slices(np.vstack(ds)) \\\n",
    "                                     .cache().shuffle(dl).batch(self.settings[\"batch_size\"],drop_remainder=True) \\\n",
    "                                     .map(self.normaliseDatapoint, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "                                     .prefetch(tf.data.experimental.AUTOTUNE) \\\n",
    "                                     for ds, dl in zip((self._test_pure, self._train_pure), (self.test_num_datapoints, self.train_num_datapoints)))\n",
    "        \n",
    "    def __str__(self):\n",
    "        with np.printoptions(precision=3, suppress=True, sign=' '):\n",
    "            return  f\"Dataset {self.name}\\n\"+\\\n",
    "                f\"Path: {self.path}\\nSettings: {json.dumps(self.settings,indent=2)}\\n\"+\\\n",
    "                f\"Number of sequences: {len(self.sequences)}, with total length: {sum([len(s) for s in self.sequences])}\\n\"+\\\n",
    "                f\"Train: {self.train_num_datapoints} datapoints of {self.train_num_sequences} sequences \\n\"+\\\n",
    "                f\"Test: {self.test_num_datapoints} datapoints of {self.test_num_sequences} sequences \\n\"+\\\n",
    "                f\"Train: {self.train}\\nTest:  {self.test} \\n\"+\\\n",
    "                f\"Covariance test:\\n{self.test_cov}\\nEigenvectors (-values below):\\n{self.test_eigVects}\\n\\n {self.test_eigVals} \\n\"+\\\n",
    "                f\"Covariance train:\\n{self.train_cov}\\nEigenvectors (-values below):\\n{self.train_eigVects}\\n\\n {self.train_eigVals} \\n\"\n",
    "        \n",
    "    @tf.function\n",
    "    def transformEnvironment(self, environment):\n",
    "        \"\"\"Transforms the Environment (model input): target, box1, box2 \n",
    "        Transforms from local cartesian to local polar coordinate with inverse distance\n",
    "        Value range angles: -1 to 1, with 0 being forwards\n",
    "                    distance: 0=infinite distance, theoretical 1=same position\n",
    "        \"\"\"\n",
    "        def getDist(pos): return tf.math.reciprocal_no_nan(tf.norm(pos, axis=-1))*10 # calulate inverse distance to position\n",
    "        def getAngle(pos): return tf.math.atan2(pos[:,1], pos[:,0])/np.pi # calculate angle (radians/pi) to position\n",
    "        def getRotation(delta_rot): return delta_rot/np.pi # calculate relative rotation\n",
    "        return tf.stack([\n",
    "                getDist(environment[:,0:2]), # distance to target\n",
    "                getAngle(environment[:,0:2]),# angle to target\n",
    "                getDist(environment[:,2:4]), # distance to box1\n",
    "                getAngle(environment[:,2:4]),# angle to box1\n",
    "                getRotation(environment[:,4]),# rotation of box 1\n",
    "                getDist(environment[:,5:7]), # distance to box 2\n",
    "                getAngle(environment[:,5:7]),# angle to box2\n",
    "                getRotation(environment[:,7]) # rotation of box 2 \n",
    "               ], axis=1)\n",
    "\n",
    "    def drawPoles(self, img, boxPose, boxsize):\n",
    "        \"\"\"Draws a pole with 5x30 box\n",
    "         param img: image to draw on\n",
    "         param boxpose: pose (position and rotation) of box\n",
    "         param boxsize: sidelength of box\n",
    "        \"\"\"\n",
    "        angle = boxPose[2]\n",
    "        localOffset = boxsize/2.+15\n",
    "        a = 0.16514867741462683827912828964394 # diagonal angle in a 5x30 rectangle\n",
    "        l = 15.206906325745549222499210613005 # half diagonal in a 5x30 rectangle\n",
    "\n",
    "        si, co = math.sin(angle+a), math.cos(angle+a)\n",
    "        siM, coM = math.sin(angle-a), math.cos(angle-a)\n",
    "        cv2.fillConvexPoly(img, np.int32(np.array([[-co,-si],[-coM,-siM],[co,si],[coM,siM]])*l+\\\n",
    "            np.array(boxPose[:2])+(0,300)+(math.cos(angle)*localOffset, math.sin(angle)*localOffset)), (0,0,1))\n",
    "\n",
    "    def drawSquare(self, img, pose, size): \n",
    "        \"\"\"Draws a box on an image, potentially with pole\n",
    "         param img: Image to draw on\n",
    "         param pose: Pose (position and rotation) of the center of the square\n",
    "         param size: size of the square\n",
    "        \"\"\"\n",
    "        angle = pose[2] + math.pi/4\n",
    "        the_size = size/math.sqrt(2)\n",
    "        co, si = np.cos(angle)*the_size, np.sin(angle)*the_size\n",
    "        cv2.fillConvexPoly(img, np.int32(np.array([[-si,co],[co,si],[si, -co],[-co, -si]])+np.array(pose[:2]))+(0,300), (0,0,1))\n",
    "        self.drawPoles(img, pose, size)\n",
    "\n",
    "    def _getRGB_cv(self, feature):\n",
    "        \"\"\"Plot a point in the dataset\n",
    "         param feature: The flat feature vector of the dataset (len(feature) == 8) \n",
    "        \"\"\"\n",
    "        img = np.zeros((600,600,3), dtype=np.float32) # create empty canvas\n",
    "        cv2.circle(img, (int(feature[0]),int(feature[1]+300)), 10, (1,0,0), -1) # draw target\n",
    "        self.drawSquare(img, feature[2:5], 20)\n",
    "        self.drawSquare(img, feature[5:8], 30)\n",
    "        return [img]\n",
    "    \n",
    "    @tf.function\n",
    "    def transformEnvironment_to_rgb(self, environment):\n",
    "        \"\"\" Transforms the environment to rgb images\n",
    "         param environment: feature vector\n",
    "        \"\"\"\n",
    "        @tf.function\n",
    "        def getRGB_tf(env):\n",
    "            return tf.numpy_function(self._getRGB_cv, [env], tf.float32)\n",
    "        return tf.reshape(tf.map_fn(getRGB_tf, environment), (self.settings['batch_size'],600,600,3))\n",
    "    \n",
    "    @tf.function\n",
    "    def normaliseDatapoint(self, data_batch):\n",
    "        \"\"\" Normalises the Datapoint. Takes a batch (batch_size x 12)\n",
    "        Returns the (feature, label) structure of feature = normalised Environment and label = normalised Velocities\"\"\"\n",
    "        environment, velocity = data_batch[:,4:], data_batch[:,:4]\n",
    "        velocity *= self.VELOCITY_FACTORS\n",
    "        if(self.settings['filter_zeros']):\n",
    "            normalisedVel, _ = tf.linalg.normalize(velocity, axis=-1)\n",
    "        else: \n",
    "            normalisedVel = velocity\n",
    "            print(\"Warning: Velocities not normalised\")\n",
    "        normalisedEnv = self.transformEnvironment(environment)\n",
    "        return normalisedEnv, normalisedVel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Benchmark tests for efficient loading\n",
    "    def benchmark(dataset, num_epochs=2):\n",
    "        def add(a): # placeholder method for a training step\n",
    "            pass\n",
    "            #c=a+1\n",
    "        import time\n",
    "        start_time = time.perf_counter()\n",
    "        for epoch_num in range(num_epochs):\n",
    "            for featBatch, labelBatch in dataset:\n",
    "                # Performing a training step\n",
    "                add(featBatch)\n",
    "                pass\n",
    "        tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
    "    path= \"../Datasets/Dataset_square_boxes/FoP/\"\n",
    "    print(\"Benchmarks:\\n\")\n",
    "    benchmark(Dataset2d(path,{}).train, num_epochs = 5)\n",
    "    benchmark(Dataset2d(path,{\"batch_size\":\"sequence\"}).train, num_epochs = 5)\n",
    "    benchmark(Dataset2d(path,{'render_images':True, 'batch_size':4}).test, num_epochs = 5)\n",
    "    benchmark(Dataset2d(path,{'render_images':True, 'render_poles':True, 'batch_size':4}).test, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Model\n",
    "def storeModel(model, path):\n",
    "    \"\"\"Stores the model as json and weights in the folder defined by path\"\"\"\n",
    "    with open(f\"{path}/model.json\", \"w\") as f:\n",
    "        f.write(model.to_json())\n",
    "    model.save_weights(f\"{path}/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    eigLayer = custom_layers.Eigenvector_layer(returnEigValues=True) # Triggers constant tf retracing if in function, therefore is outside\n",
    "def plotDatapoint(feature, label, figsize=(5,5), model=None, loss=None, useEigenvectors=False, useSigma=False, custom_func=None, printTexts=True):\n",
    "    \"\"\"Plot a point in the dataset. Handles both rgb labels as well as flat vectors of shape (8,)\n",
    "     param feature: Featurevector (model input) as environment\n",
    "     param label: The label to the situation\n",
    "     param figsize: Size of figures. Default: (5,5) \n",
    "     param model: Optionally, apply this model to the data. Default: None, \n",
    "     param loss: Optionally, apply this loss to the model data. Default: None, \n",
    "     param useEigenvectors: Whether eigenvectors are used. Default: False, \n",
    "     param useSigma: Whether the network directly outputs covariances. Default: False, \n",
    "     param custom_func: An optional function to be applied on the data as custom_func(feature, label, model, loss). Default: None, \n",
    "     param printTexts: Whether to print texts. Default: True\n",
    "    \"\"\"\n",
    "    pprint = print if printTexts else lambda _:None\n",
    "    def transformPose(pose):\n",
    "        pos = [func((.5-pose[1])*np.pi)/(pose[0]/10) for func in (np.sin, np.cos)]\n",
    "        if len(pose)>2:\n",
    "            rot = pose[2]*np.pi\n",
    "            return pos+[rot]\n",
    "        return pos\n",
    "    def rotate2dVector(vector, angle):\n",
    "        co, si = np.cos(angle), np.sin(angle)\n",
    "        R = np.array([ [co, -si], [si, co] ])\n",
    "        return np.matmul(R, vector)\n",
    "    def drawBox(ax, pose, width, height, color='b'):\n",
    "        offset = rotate2dVector([[-width/2],[-height/2]], pose[2])\n",
    "        patch = patches.Rectangle((pose[0]+offset[0], pose[1]+offset[1]), width,height, angle=np.degrees(pose[2]),linewidth=0,edgecolor='none',facecolor=color)\n",
    "        ax.add_patch(patch)\n",
    "    def drawTarget(ax, pose, radius=10):\n",
    "        ax.add_patch(patches.Circle(pose, radius, facecolor='r'))\n",
    "    def getArrowTip(lines, scale = 1.):\n",
    "        vec = (lines[-2]-lines[-1])*scale\n",
    "        return [lines[-1]+rotate2dVector(vec, np.radians(20*a)) for a in (1,-1)]+[lines[-1]]\n",
    "    def drawVel(vel, externalPointOffset=30, color='g'): # draw velocity arrows\n",
    "        speedPerDim = np.array([50., 50., 70., .01])\n",
    "        if isinstance(vel, tf.Tensor): vel = vel.numpy()\n",
    "        if np.linalg.norm(vel[:2]) > 1.: # normalise XY movement\n",
    "            vel[:2]  /= np.linalg.norm(vel[:2])\n",
    "        scaledDof = vel * speedPerDim * [0.2, 0.2, 0.2, 100]\n",
    "        centerPoints = [0,0]\n",
    "        angles=[0]\n",
    "        for i in range(10):\n",
    "            centerPoints.append(centerPoints[-1] + rotate2dVector(scaledDof[:2], angles[-1]))\n",
    "            angles.append(angles[-1] + np.radians(scaledDof[2]))\n",
    "        externalPointsToDraw = (0,-externalPointOffset), (0,externalPointOffset)\n",
    "        for p in externalPointsToDraw:\n",
    "            outerPoints = [c + rotate2dVector(p, a) for c,a in zip(centerPoints, angles)]\n",
    "            outerPoints = np.array(outerPoints + getArrowTip(outerPoints))\n",
    "            plt.plot(outerPoints[:,0], outerPoints[:,1],color)\n",
    "            gripperPoints = [np.array(p)+[abs(p[1]*(3/4)),p[1]*abs(scaledDof[3])], np.array(p)+[abs(p[1]*(3/4)),0]]\n",
    "            gripperPoints = gripperPoints if np.sign(scaledDof[3])>0 else [gripperPoints[1],gripperPoints[0]]\n",
    "            gripperPoints = np.array(gripperPoints + getArrowTip(gripperPoints, 0.5))\n",
    "            plt.plot(gripperPoints[:,0], gripperPoints[:,1], color)\n",
    "        \n",
    "    if isinstance(feature, tf.Tensor):\n",
    "        feature_np = feature.numpy()\n",
    "    else: feature_np = feature\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.gca()    # Get the current reference\n",
    "    ax.set_aspect('equal')\n",
    "    if feature_np.ndim == 1: # assuming the feature vector to have size 8\n",
    "        target = transformPose(feature_np[:2])\n",
    "        box1, box2 = transformPose(feature_np[2:5]), transformPose(feature_np[5:8])\n",
    "        plt.xlim(-400,400)\n",
    "        plt.ylim(400,-400)\n",
    "        # Draw boxes / target\n",
    "        drawBox(ax, box1, 20,20)\n",
    "        drawBox(ax, box2, 30,30)\n",
    "        drawTarget(ax, target)\n",
    "    else:\n",
    "        # assuming the feature vector to be an image\n",
    "        feature_np = feature_np+1-np.sum(feature_np,axis=-1, keepdims=True)\n",
    "        plt.imshow(feature_np, aspect='equal', extent=(-0.5, feature_np.shape[1]-.5, feature_np.shape[0]-feature_np.shape[0]/2, -feature_np.shape[0]/2))\n",
    "    # Draw robot:\n",
    "    drawBox(ax, (0,0,0), 20,70, color='r')\n",
    "    drawBox(ax, (20,-30,0), 20,10, color='black')\n",
    "    drawBox(ax, (20,30,0), 20,10, color='black')\n",
    "    drawVel(label)\n",
    "    with np.printoptions(precision=3, suppress=True, sign=' '):\n",
    "        label = tf.expand_dims(label,0)\n",
    "        pprint(f\"velocity: {label.numpy()}\")\n",
    "        pprint(f\"state: {feature_np}\")\n",
    "        if model != None:\n",
    "            pred = model.predict(tf.expand_dims(tf.convert_to_tensor(feature), 0))\n",
    "            pprint(f\"Prediction:\\n{pred}\")\n",
    "            if loss != None:\n",
    "                pprint(f\"\\nLoss:\\n{loss(label, pred)}\")\n",
    "            if not useEigenvectors and not useSigma:        \n",
    "                drawVel(np.squeeze(pred[0]),60, 'orange')\n",
    "            else:\n",
    "                if useEigenvectors:\n",
    "                    eigVects, eigVals = eigLayer(tf.convert_to_tensor(pred))\n",
    "                else:\n",
    "                    eigVals, eigVects = tf.linalg.eigh(pred) # useSigma != True\n",
    "                    eigVals, eigVects = tf.reverse(eigVals, [-1]), tf.reverse(eigVects, [-1])\n",
    "                drawVel(eigVects[0,:,1],80, 'yellow')                \n",
    "                drawVel(eigVects[0,:,0],60, 'orange')\n",
    "                pprint(f\"\\nEigvectors:\\n{eigVects}\")\n",
    "                pprint(f\"\\nEigvalues:\\n{eigVals}\")\n",
    "    if custom_func != None:\n",
    "        custom_func(feature, label, model, loss)\n",
    "    plt.show()\n",
    "\n",
    "def plotDatapointBatch(dataset, numPlots=1, figsize=(20,20), model= None, loss=None, useEigenvectors=False, useSigma=False, custom_func=None, printTexts=True):\n",
    "    \"\"\"Plots Batches of the dataset. Default: only show first. Handles both rgb labels as well as flat vectors of shape (8,)\n",
    "     param dataset: Dataset of which the batches are to be generated \n",
    "     param figsize: Size of figures. Default: (20,20) \n",
    "     param model: Optionally, apply this model to the data. Default: None, \n",
    "     param loss: Optionally, apply this loss to the model data. Default: None, \n",
    "     param useEigenvectors: Whether eigenvectors are used. Default: False, \n",
    "     param useSigma: Whether the network directly outputs covariances. Default: False, \n",
    "     param custom_func: An optional function to be applied on the data as custom_func(feature, label, model, loss). Default: None, \n",
    "     param printTexts: Whether to print texts. Default: True\n",
    "    \"\"\"\n",
    "    for featureBatch, labelBatch in dataset:\n",
    "        for feature,label in zip(featureBatch, labelBatch):\n",
    "            plotDatapoint(feature, label, figsize, model=model, loss=loss, useEigenvectors=useEigenvectors, useSigma=useSigma, custom_func=custom_func, printTexts=printTexts)\n",
    "            numPlots -= 1\n",
    "            if not numPlots: break\n",
    "        if not numPlots: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import import_ipynb\n",
    "    MomentMetrics = import_ipynb.NotebookLoader(sys.path).load_module(\"MomentMetrics\")\n",
    "    # Test:\n",
    "    datasetPath= \"../Datasets/Dataset_boxes_with_poles/\"\n",
    "    modelPath= \"../JS_Simulation/namedModels/empty_model/\"\n",
    "    ds = Dataset2d(datasetPath, {\"batch_size\":32, \"train_test_ratio\":2})\n",
    "    test = ds.test\n",
    "    with open(f\"{modelPath}/model.json\", \"r\") as f:\n",
    "        model = tf.keras.models.model_from_json(f.read(), custom_objects={\n",
    "            'custom_layers':custom_layers, \n",
    "            'PathNormalisation_layer':custom_layers.PathNormalisation_layer,\n",
    "            'Covariance_layer':custom_layers.Covariance_layer})\n",
    "    model.load_weights(f\"{modelPath}/model_weights.h5\")\n",
    "    \n",
    "    plotDatapointBatch(test, figsize=(5,5), numPlots=1, model=model, \n",
    "                       loss=MomentMetrics.momentLoss, useEigenvectors=False, useSigma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
